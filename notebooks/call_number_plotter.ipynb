{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad027d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.errors import EmptyDataError \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from datetime import time, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3dab0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method takes in paramaters:\n",
    "# 1) recover_folder: Name of the folder where the detections are stored.\n",
    "# 2) AUDIO_DUR: The AudioMoth's configuration for the length of each recording.\n",
    "\n",
    "# This method returns:\n",
    "# - A DataFrame object that has columns:\n",
    "#   - File Names, Date, Start Time, End Time, # of LF detections, # of HF detections\n",
    "#   - File Names are strings and # of LF/HF detections are integers.\n",
    "#   - Times are in UTC format and Dates are datetime.datetime objects.\n",
    "\n",
    "def generate_df(recover_folder, audio_dur=pd.DateOffset(minutes=29, seconds=55)):\n",
    "\n",
    "    # detection_dir is the recover-DATE-UNIT_NUM-detect folder where our detections are.\n",
    "    detection_dir = f\"detections/{recover_folder}\"\n",
    "\n",
    "    # Construct path object linked to the directory of files for datetime-parsing\n",
    "    file_dir = Path(detection_dir)\n",
    "    # We use this to only extract the original file names of the recordings.\n",
    "    # The detection files will be assembled below.\n",
    "    sorted_files = sorted(file_dir.glob('hf_*.txt'))\n",
    "\n",
    "    # Create empty DataFrame object with all the required columns    \n",
    "    df = pd.DataFrame(columns=[\"File Names\", \"Date\", \"Start Time (UTC)\",\n",
    "                       \"End Time (UTC)\", \"# of LF detections\", \"# of HF detections\"])\n",
    "    \n",
    "    # Iterate through all file paths to extract and store table information for each file\n",
    "    for i, file in enumerate(sorted_files):\n",
    "        # Extract name of each file as it is\n",
    "        file_name = file.name\n",
    "        # Extracting the datetime object from the name of each file\n",
    "        file_info = dt.strptime(file_name, \"hf_%Y%m%d_%H%M%S.WAV.txt\")\n",
    "\n",
    "        # Extract recording name, date, start time, and end time for each file\n",
    "        recording_name = file_info.strftime(\"%Y%m%d_%H%M%S.WAV\")\n",
    "        date = file_info.date()\n",
    "        s_time = file_info.time()\n",
    "        e_time = (file_info+audio_dur).time()\n",
    "\n",
    "        # Calling read_detection to return the table of selections as a dataframe\n",
    "        # The detections appear twice: in waveform view and spectrogram view, \n",
    "        # so we half the total number of detections\n",
    "        lf_file_detections = read_detection(detection_dir, recording_name, \"lf\")\n",
    "        num_lf_detections = lf_file_detections.shape[0]/2\n",
    "        hf_file_detections = read_detection(detection_dir, recording_name, 'hf')\n",
    "        num_hf_detections = hf_file_detections.shape[0]/2\n",
    "        \n",
    "        # Add new row with the extracted information\n",
    "        df.loc[len(df.index)] = [recording_name, date, s_time, e_time, num_lf_detections, num_hf_detections]\n",
    "        \n",
    "    # This section checks if the last date has information from 0:00 to 24:00\n",
    "    # If it doesn't we pad the date with time information so our plots can be comparable\n",
    "    # The # of LF/HF detections will be NaN in the dataframe.\n",
    "    while (s_time != time(23, 30)):\n",
    "        date = df.loc[len(df.index)-1][\"Date\"]\n",
    "        s_time = (dt.combine(date, s_time)+pd.DateOffset(minutes=30)).time()\n",
    "        file_info = dt.combine(date, s_time)\n",
    "        recording_name = file_info.strftime(\"%Y%m%d_%H%M%S.WAV\")\n",
    "        e_time = (file_info+audio_dur).time()\n",
    "        df.loc[len(df.index)] = [recording_name, date, s_time, e_time, None, None]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93a72428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given parameters:\n",
    "# 1) detection_dir is the recover-DATE-UNIT_NUM-detect folder\n",
    "# 2) recording_name is the name of our recording: DATE_TIME.WAV\n",
    "# 4) det_type can either be 'lf' or 'hf'\n",
    "\n",
    "# Output:\n",
    "# The table of detections following the format of RavenPro\n",
    "\n",
    "def read_detection(detection_dir, recording_name, det_type):\n",
    "    \n",
    "    file_name = f\"{det_type}_{recording_name}.txt\"\n",
    "    file_path = f\"{detection_dir}/{file_name}\"\n",
    "    \n",
    "    if (Path(file_path).is_file()):\n",
    "        try:\n",
    "            df_detection = pd.read_csv(file_path, sep='\\t')\n",
    "        except EmptyDataError:\n",
    "            print(f\"{file_path} is empty\")\n",
    "            \n",
    "    return df_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "838d3832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_separate(df, save=True):\n",
    "    \n",
    "    # To plot each day's activity separately, group by rows that have the same date\n",
    "    # We need a list of unique dates from our detection files\n",
    "    unique_dates = df[\"Date\"].unique()\n",
    "\n",
    "    s_times = []\n",
    "    i=0\n",
    "    s_times.append(time(0, 0, 0))\n",
    "    while (s_times[i] != time(hour=23, minute=30, second=0)):\n",
    "        old_dt = (dt.combine(unique_dates[0], s_times[i]))\n",
    "        new_dt = old_dt+pd.DateOffset(minutes=30)\n",
    "        s_times.append(new_dt.time())\n",
    "        i = i+1\n",
    "        \n",
    "    print(s_times)\n",
    "    \n",
    "    for date in unique_dates:\n",
    "        day_df = df.loc[df['Date'] == date]\n",
    "        \n",
    "        fig = day_df.plot.bar(x=\"Start Time (UTC)\", figsize=(12, 4), fontsize=12, rot=45)\n",
    "        fig.set_title(date, fontsize=14)\n",
    "        \n",
    "        if save:\n",
    "            save_folder = f\"../results/raven_energy_detector_raw/call_num_summary/{recover_folder}/FIGS\"\n",
    "            save_dir = Path(save_folder)\n",
    "            save_dir.mkdir(parents=True, exist_ok=True)\n",
    "            save_path = Path(f\"{save_folder}/{date}.png\")\n",
    "            fig.get_figure().savefig(save_path, facecolor='w')\n",
    "            \n",
    "        fig.set_xticks(fig.get_xticks()[::2])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "73783fdc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_total(df):\n",
    "    \n",
    "    fig = df.plot.bar(x=\"Start Time (UTC)\", figsize=(12, 4), fontsize=12, rot=45)\n",
    "    fig.set_title(\"Total Deployment Session\", fontsize=14)\n",
    "    fig.set_xticks(fig.get_xticks()[::4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7923be15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# These are constants that we absolutely need to know before running any scripts\n",
    "\n",
    "# Constant DATE is the date of our recovered data that we are extracting detections from\n",
    "DATE = \"20220725\"\n",
    "# Constant SD_CARD_NUM is the SD CARD # that had been deployed for that session\n",
    "SD_CARD_NUM = \"010\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "71fce4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "recover_folder = f\"recover-{DATE}-{SD_CARD_NUM}-detect\"\n",
    "df = generate_df(recover_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "52322224",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.time(0, 0), datetime.time(0, 30), datetime.time(1, 0), datetime.time(1, 30), datetime.time(2, 0), datetime.time(2, 30), datetime.time(3, 0), datetime.time(3, 30), datetime.time(4, 0), datetime.time(4, 30), datetime.time(5, 0), datetime.time(5, 30), datetime.time(6, 0), datetime.time(6, 30), datetime.time(7, 0), datetime.time(7, 30), datetime.time(8, 0), datetime.time(8, 30), datetime.time(9, 0), datetime.time(9, 30), datetime.time(10, 0), datetime.time(10, 30), datetime.time(11, 0), datetime.time(11, 30), datetime.time(12, 0), datetime.time(12, 30), datetime.time(13, 0), datetime.time(13, 30), datetime.time(14, 0), datetime.time(14, 30), datetime.time(15, 0), datetime.time(15, 30), datetime.time(16, 0), datetime.time(16, 30), datetime.time(17, 0), datetime.time(17, 30), datetime.time(18, 0), datetime.time(18, 30), datetime.time(19, 0), datetime.time(19, 30), datetime.time(20, 0), datetime.time(20, 30), datetime.time(21, 0), datetime.time(21, 30), datetime.time(22, 0), datetime.time(22, 30), datetime.time(23, 0), datetime.time(23, 30)]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([00:00:00, 00:30:00, 01:00:00, 01:30:00, 02:00:00, 02:30:00, 03:00:00,\\n       03:30:00, 04:00:00, 04:30:00, 05:00:00, 05:30:00, 06:00:00, 06:30:00,\\n       07:00:00, 07:30:00, 08:00:00, 08:30:00, 09:00:00, 09:30:00, 10:00:00,\\n       10:30:00, 11:00:00, 11:30:00, 12:00:00, 12:30:00, 13:00:00, 13:30:00,\\n       14:00:00, 14:30:00, 15:00:00, 15:30:00, 16:00:00, 16:30:00, 17:00:00,\\n       17:30:00, 18:00:00, 18:30:00, 19:00:00, 19:30:00, 20:00:00, 20:30:00,\\n       21:00:00, 21:30:00, 22:00:00, 22:30:00, 23:00:00, 23:30:00],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_separate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [73]\u001b[0m, in \u001b[0;36mplot_separate\u001b[0;34m(df, save)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m unique_dates:\n\u001b[1;32m     19\u001b[0m     day_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m date]\n\u001b[0;32m---> 21\u001b[0m     fig \u001b[38;5;241m=\u001b[39m \u001b[43mday_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m45\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     fig\u001b[38;5;241m.\u001b[39mset_title(date, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save:\n",
      "File \u001b[0;32m~/miniconda3/envs/bat-analysis/lib/python3.10/site-packages/pandas/plotting/_core.py:1131\u001b[0m, in \u001b[0;36mPlotAccessor.bar\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;124;03m    See Also\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_bar_or_line_doc)\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbar\u001b[39m(\u001b[38;5;28mself\u001b[39m, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;124;03m    Vertical bar plot.\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;124;03m    other axis represents a measured value.\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bat-analysis/lib/python3.10/site-packages/pandas/plotting/_core.py:937\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(x) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mholds_integer():\n\u001b[1;32m    936\u001b[0m     x \u001b[38;5;241m=\u001b[39m data_cols[x]\n\u001b[0;32m--> 937\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m, ABCSeries):\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx must be a label or position\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    939\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mset_index(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/bat-analysis/lib/python3.10/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/bat-analysis/lib/python3.10/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bat-analysis/lib/python3.10/site-packages/pandas/core/indexes/base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5841\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index([00:00:00, 00:30:00, 01:00:00, 01:30:00, 02:00:00, 02:30:00, 03:00:00,\\n       03:30:00, 04:00:00, 04:30:00, 05:00:00, 05:30:00, 06:00:00, 06:30:00,\\n       07:00:00, 07:30:00, 08:00:00, 08:30:00, 09:00:00, 09:30:00, 10:00:00,\\n       10:30:00, 11:00:00, 11:30:00, 12:00:00, 12:30:00, 13:00:00, 13:30:00,\\n       14:00:00, 14:30:00, 15:00:00, 15:30:00, 16:00:00, 16:30:00, 17:00:00,\\n       17:30:00, 18:00:00, 18:30:00, 19:00:00, 19:30:00, 20:00:00, 20:30:00,\\n       21:00:00, 21:30:00, 22:00:00, 22:30:00, 23:00:00, 23:30:00],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "plot_separate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60144980",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_total(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2fe515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
